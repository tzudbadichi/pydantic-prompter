{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Pydantic Prompter","text":"<p>Pydantic Prompter is a lightweight tool designed for effortlessly constructing prompts and obtaining Pydantic objects as outputs.</p> <p>This library leverages the OpenAi function calling API for its functionality.</p> <p>The design of the library's API draws inspiration from DeclarAI</p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#basic-usage","title":"Basic usage","text":"<p>To utilize Pydantic Prompter with Jinja2 templates, follow the example below:</p> <pre><code>from pydantic_prompter import Prompter\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-....\"\n\n\nclass RecommendedEntry(BaseModel):\n    id: str\n    name: str\n    reason: str = Field(description=\"Why this entry fits the query\", default=\"\")\n\n\nclass RecommendationResults(BaseModel):\n    title: str\n    entries: List[RecommendedEntry]\n\n\n@Prompter(llm=\"openai\", jinja=True, model_name=\"gpt-3.5-turbo-16k\")\ndef rank_recommendation(entries, query) -&gt; RecommendationResults:\n    \"\"\"\n    - system: You are a movie ranking expert\n    - user: |\n        Which of the following JSON entries fit best to the query.\n        order by best fit descending\n        Base your answer ONLY on the given JSON entries\n\n    - user: &gt;\n        The JSON entries:\n        {{ entries }}\n\n    - user: \"query: {{ query }}\"\n\n    \"\"\"\n\n\nmy_entries = (\n    '[{\"text\": \"Description: Four everyday suburban guys come together as a ....'\n)\nprint(rank_recommendation(entries=my_entries, query=\"Romantic comedy\"))\n\n# &gt;&gt;&gt; title='Romantic Comedy' entries=[RecommendedEntry(id='2312973', \\\n#       name='The Ugly Truth', reason='Romantic comedy genre')]\n\n\n# ==Debug you query==\nprint(rank_recommendation.build_string(entries=my_entries, query=\"Romantic comedy\"))\n\n# &gt;&gt;&gt; system: You are a movie ranking expert\n#     user: Which of the following JSON entries fit best to the query.\n#     order by best fit descending\n#     Base your answer ONLY on the given JSON entries\n#     user: The JSON entries: [{\"text\": \"Description: Four everyday suburban guys come together as a ....\n#     user: query: Romantic comedy\n</code></pre>"},{"location":"#simple-string-formatting","title":"Simple string formatting","text":"<p>For injecting conversation history through straightforward string formatting, refer to this example:</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_prompter import Prompter\n\n\nclass QueryGPTResponse(BaseModel):\n    google_like_search_term: str\n\n\n@Prompter(llm=\"openai\", model_name=\"gpt-3.5-turbo\")\ndef search_query(history) -&gt; QueryGPTResponse:\n    \"\"\"\n    {history}\n\n    - user: |\n        Generate a Google-like search query text\n        encompassing all previous chat questions and answers\n    \"\"\"\n\n\nhistory = \"\"\"\n- assistant: what genre do you want to watch?\n- user: Comedy\n- assistant: do you want a movie or series?\n- user: Movie\n\"\"\"\nres = search_query.build_string(history=history)\nprint(res)\n\n# &gt;&gt;&gt; assistant: what genre do you want to watch?\n#     user: Comedy\n#     assistant: do you want a movie or series?\n#     user: Movie\n#     user: Generate a Google-like search query text\n#     encompassing all previous chat questions and answers\n</code></pre>"},{"location":"#jinja2-advance-usage","title":"Jinja2 advance usage","text":"<p>For more advanced usage involving Jinja2 loops to inject conversation history, consider the following code snippet:</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_prompter import Prompter\n\n\nclass QueryGPTResponse(BaseModel):\n    google_like_search_term: str\n\n\n@Prompter(llm=\"openai\", jinja=True, model_name=\"gpt-3.5-turbo\")\ndef search_query(history) -&gt; QueryGPTResponse:\n    \"\"\"\n    {%- for line in history %}\n     {{ line }}\n    {% endfor %}\n\n    - user: |\n        Generate a Google-like search query text\n        encompassing all previous chat questions and answers\n    \"\"\"\n\n\nhistory = [\n    \"- assistant: what genre do you want to watch?\",\n    \"- user: Comedy\",\n    \"- assistant: do you want a movie or series?\",\n    \"- user: Movie\",\n]\nres = search_query.build_string(history=history)\nprint(res)\n\n# &gt;&gt;&gt; assistant: what genre do you want to watch?\n#     user: Comedy\n#     assistant: do you want a movie or series?\n#     user: Movie\n#     user: Generate a Google-like search query text\n#     encompassing all previous chat questions and answers\n</code></pre>"},{"location":"#best-practices","title":"Best practices","text":"<p>When using Pydantic Prompter, it is recommended to explicitly specify the parameter name you wish to retrieve, as demonstrated in the example below, where title is explicitly mentioned:</p> <p><pre><code>class RecommendationTitleResponse(BaseModel):\n    title: str = Field(description=\"4 to 6 words title\")\n\n\n@Prompter(llm=\"openai\", jinja=True, model_name=\"gpt-3.5-turbo-16k\")\ndef recommendation_title(json_entries) -&gt; RecommendationTitleResponse:\n    \"\"\"\n    - user: &gt;\n        Based on the JSON entries, suggest a minimum 4 words and maximum 6 words title\n\n    - user: &gt;\n        The JSON entries:\n        {{ json_entries }}\n\n    \"\"\"\n</code></pre> Avoid the following practice where the parameter name is not explicitly stated:</p> <p><pre><code>class BaseResponse(BaseModel):\n    text: str = Field(description=\"4 to 6 words text\")\n\n\n@Prompter(llm=\"openai\", jinja=True, model_name=\"gpt-3.5-turbo-16k\")\ndef recommendation_title(json_entries) -&gt; BaseResponse:\n    \"\"\"\n    ...\n    \"\"\"\n</code></pre> Adhering to these best practices will ensure clarity and precision when using Pydantic Prompter.</p>"},{"location":"#debugging-and-logging","title":"Debugging and logging","text":"<p>You can view info and/or debugging logging using the following snippet:</p> <p><pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO)\nlogging.getLogger(\"pydantic_prompter\").setLevel(logging.DEBUG)\n</code></pre> Resulting <pre><code>DEBUG:pydantic_prompter:Using OpenAI provider with model gpt-3.5-turbo\nDEBUG:pydantic_prompter:Using PydanticParser\nDEBUG:pydantic_prompter:Calling with prompt: \n {'role': 'user', 'content': 'say hi'}\nDEBUG:pydantic_prompter:Response from llm: \n {\n  \"response\": \"Hi there!\"\n }\n</code></pre></p>"},{"location":"ai_services/","title":"AI services","text":""},{"location":"ai_services/#using-aws-bedrock","title":"Using AWS Bedrock","text":"<p>If you want to use AWS Bedrock you should install bedrock-python-sdk</p> <pre><code>pip install https://d2eo22ngex1n9g.cloudfront.net/Documentation/SDK/bedrock-python-sdk.zip\n</code></pre> <p>setup your AWS creds </p> <pre><code>from pydantic_prompter import Prompter\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport os\n\nos.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\nos.environ[\"AWS_ACCESS_KEY_ID\"] = \"...\"\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"...\"\nos.environ[\"AWS_SESSION_TOKEN\"] = \"...\"\n\n\nclass MyChildren(BaseModel):\n    num_of_children: int\n    children_names: List[str] = Field(description=\"The names of my children\")\n\n\n@Prompter(llm=\"bedrock\", model_name=\"anthropic.claude-v1\")\ndef me_and_mu_children(name) -&gt; MyChildren:\n    \"\"\"\n    - user: hi, my name is {name} and my children are called, aa, bb, cc\n    - user: |\n        how many children do I have and what's their names?\n    \"\"\"\n\n\nprint(me_and_mu_children(name=\"Ofer\"))\n</code></pre>"},{"location":"prompt_templates/","title":"Prompts","text":""},{"location":"prompt_templates/#prompts","title":"Prompts","text":""},{"location":"prompt_templates/#working-with-custom-prompts","title":"Working with custom prompts","text":"<p>Relevant to Anthropic models</p> <pre><code>import logging\nimport os\nfrom pydantic_prompter import Prompter\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nlogging.basicConfig(\n    level=logging.INFO,\n)\nlogging.getLogger(\"pydantic_prompter\").setLevel(logging.DEBUG)\n\nos.environ[\"TEMPLATE_PATHS__ANTHROPIC\"] = \"./anthropic_custom.jinja\"\n\n\nclass MyChildren(BaseModel):\n    num_of_children: int\n    children_names: List[str] = Field(description=\"The names of my children\")\n\n\n@Prompter(llm=\"bedrock\", model_name=\"anthropic.claude-v1\")\ndef me_and_mu_children(name) -&gt; MyChildren:\n    \"\"\"\n    - user: hi, my name is {name} and my children are called, aa, bb, cc\n    - user: |\n        how many children do I have and what's their names?\n    \"\"\"\n\n\nprint(me_and_mu_children(name=\"Ofer\"))\n\n# &gt;&gt;&gt; DEBUG:pydantic_prompter:Using bedrock provider\n#     DEBUG:pydantic_prompter:Using BedRockAnthropic provider with model anthropic.claude-v1\n#     DEBUG:pydantic_prompter:Using PydanticParser\n#     INFO:pydantic_prompter:Using custom prompt from ./anthropic_custom.jinja\n#     DEBUG:pydantic_prompter:Calling with prompt:\n#      Human: You are a REST API that answers the question contained in &lt;qq&gt; tags.\n#     Your response should be in a JSON format which it's schema is specified in the ...\n#\n#     &lt;json&gt;\n#     {\n</code></pre>"},{"location":"prompt_templates/#predefined-prompts","title":"Predefined prompts","text":""},{"location":"prompt_templates/#anthropic","title":"Anthropic","text":"<pre><code>Human: You are a REST API that answers the question contained in &lt;question&gt; tags.\nYour response should be within &lt;json&gt;&lt;/json&gt; xml tags in JSON format with the schema specified in the &lt;json_schema&gt; tags.\nDO NOT add any other text other than the JSON response\n\n&lt;json_schema&gt;\n{{ schema }}\n&lt;/json_schema&gt;\n\nAssistant: OK\n\n{{ question }}\n\nAssistant: &lt;json&gt;\n</code></pre>"}]}